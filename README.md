# datalake-cloud-project

# Architecture
<img width="1127" alt="image" src="https://github.com/dinanazizi/datalake-cloud-project/assets/110298446/06fcd7b1-367e-41ae-a44c-3903d63daa30">

# Tech Stack

Technologies needed to build a *Datalake* ecosystem include:

## Apache Airflow

Apache Airflow is a platform to programmatically author, schedule, and monitor workflows. It is essential for orchestrating data pipelines within the Datalake ecosystem, ensuring that data flows smoothly and efficiently from one stage to the next.

## Dremio

Dremio is an engine required for processing various forms of data, whether it is unstructured, semi-structured, or structured. Dremio is also commonly referred to as a **Data Lake Engine.** One of its advantages is its ability to process unstructured data using *Query Like*.

## Minio Server

Minio Server is a modern object storage system similar to Amazon Web Service (AWS) S3. Minio is used as **Data Lake Storage.**

## Nessie

Nessie is a data versioning system similar to Git versioning.

## Metabase

Metabase is a data analytics platform with capabilities to create graphs, perform data queries, and generate executive summaries.
